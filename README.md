# cohen-linear-algebra

Notes and code demos in Python for linear algebra. The idea is to construct the SVD as soon as possible, then use it for everything else &mdash; from characterizing invertbility, to parametrizing the loss surface of a linear regression model with linearly dependent data columns. Some of the interesting stuff that is covered:
  * Proof of the real spectral theorem, and a code demo
  * Proof of the singular value decomposition (SVD)
  * Characterizing the loss surface of a linear regression problem
  * An extensive discussion of the Moore-Penrose pseudoinverse
  * Stability of the Gram-Schmidt algorithm

I wrote these while following the Udemy course [Complete linear algebra: theory and implementation in code](https://www.udemy.com/course/linear-algebra-theory-and-implementation/) by [Prof. Mike X Cohen](http://mikexcohen.com/). Check the course out if you're a beginner interested in machine learning. :=)

<br>

## Quick links

* [Proofs involving the Moore-Penrose pseudoinverse](https://en.wikipedia.org/wiki/Proofs_involving_the_Moore%E2%80%93Penrose_inverse)
* [KaTeX Supported Functions](https://katex.org/docs/supported.html)


<br>

## References
* [Sheldon Axler. *Down With Determinants!*. The American Monthly, 1996.](https://www.maa.org/sites/default/files/pdf/awards/Axler-Ford-1996.pdf)
* [Leslie Hogben (editor), *Handbook of Linear Algebra*. CRC Press, 2014.](https://www.oreilly.com/library/view/handbook-of-linear/9781466507296/)
* [Cleve Moler. *Numerical Computing with MATLAB*. The MathWorks / SIAM, 2013.](https://www.mathworks.com/moler/index_ncm.html)
* [Peter Olver and Chehzrad Shakiban. *Applied Linear Algebra*. UTM Springer, 2018.](https://www-users.math.umn.edu/~olver/books.html)
* [Petersen & Pedersen. *The Matrix Cookbook*. v. Nov. 15, 2012.](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf)
